import streamlit as st
import cv2
import numpy as np
import base64
from openai import OpenAI
import tempfile
import os
from PIL import Image, ImageDraw, ImageFont
import io
import json
import subprocess
from datetime import datetime
import zipfile

# ç¡®ä¿å®‰è£…çš„æ˜¯ moviepy==1.0.3
from moviepy.editor import VideoFileClip

# --- 1. é…ç½®ä¸å¯†é’¥åŠ è½½ ---
st.set_page_config(
    page_title="è§†å¬è¯­è¨€åˆ†æå·¥ä½œç«™", 
    page_icon="ğŸ¬", 
    layout="wide",
    initial_sidebar_state="collapsed"
)

# API é…ç½®
try:
    VISION_API_KEY = st.secrets["vision"]["api_key"]
    VISION_BASE_URL = st.secrets["vision"]["base_url"]
    VISION_MODEL = st.secrets["vision"]["model"]
    
    AUDIO_API_KEY = st.secrets["audio"]["api_key"]
    AUDIO_BASE_URL = st.secrets["audio"]["base_url"]
    AUDIO_MODEL = st.secrets["audio"]["model"]
except Exception as e:
    st.error(f"âš ï¸ é…ç½®ç¼ºå¤±: {e}ã€‚è¯·æ£€æŸ¥ secrets.toml")
    st.stop()

# Google Sheets é…ç½®ï¼ˆå¯é€‰ï¼‰
try:
    GSHEET_CREDENTIALS = st.secrets["gsheet"]["credentials"]
    GSHEET_URL = st.secrets["gsheet"]["sheet_url"]
    GSHEET_ENABLED = True
except:
    GSHEET_ENABLED = False

# --- ç”¨æˆ·è´¦å·ç³»ç»Ÿ ---
USERS = {
    "Baihe123": "Hengxing666",
    "Shujun123": "Hengxing666",
    "Hans123": "Hengxing666",
    "Heixin123": "Hengxing666",
}

def check_login():
    """æ£€æŸ¥ç™»å½•çŠ¶æ€"""
    return st.session_state.get("logged_in", False)

def get_current_user():
    """è·å–å½“å‰ç™»å½•ç”¨æˆ·"""
    return st.session_state.get("username", None)

def log_usage(username, feature, options=""):
    """è®°å½•ä½¿ç”¨æ—¥å¿—åˆ° Google Sheets"""
    if not GSHEET_ENABLED:
        return
    
    try:
        import gspread
        from google.oauth2.service_account import Credentials
        
        scopes = [
            "https://www.googleapis.com/auth/spreadsheets",
            "https://www.googleapis.com/auth/drive"
        ]
        
        creds_dict = json.loads(GSHEET_CREDENTIALS)
        credentials = Credentials.from_service_account_info(creds_dict, scopes=scopes)
        gc = gspread.authorize(credentials)
        
        sheet = gc.open_by_url(GSHEET_URL).sheet1
        
        # è®°å½•ï¼šæ—¶é—´ã€ç”¨æˆ·ã€åŠŸèƒ½ã€é€‰é¡¹
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        sheet.append_row([timestamp, username, feature, options])
        
    except Exception as e:
        st.warning(f"æ—¥å¿—è®°å½•å¤±è´¥: {e}")

# --- 2. æ ·å¼ ---
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@400;500;700;900&display=swap');

    .stApp { background-color: #0B0E14; font-family: 'Noto Sans SC', sans-serif; }
    h1, h2, h3, p, div, span, label { color: #FFFFFF !important; }
    .stMarkdown p { color: #B0B6BE !important; }

    h1 {
        font-size: 2.8rem !important; font-weight: 900 !important; text-align: center;
        margin-top: 20px; margin-bottom: 10px; letter-spacing: 2px;
        text-shadow: 0 0 20px rgba(41, 121, 255, 0.3);
    }
    .subtitle { text-align: center; color: #8E95A3 !important; font-size: 1rem; margin-bottom: 40px; }

    .stTabs [data-baseweb="tab-list"] {
        gap: 8px; background-color: transparent; border-bottom: none !important;
        display: flex; justify-content: center;
        flex-wrap: nowrap; margin-bottom: 30px;
    }
    .stTabs [data-baseweb="tab"] {
        height: 44px; border-radius: 22px; background-color: #1E232E; color: #B0B6BE !important;
        border: 1px solid #2D3342; font-size: 14px; font-weight: 500; padding: 0 30px;
        transition: all 0.2s;
    }
    .stTabs [data-baseweb="tab"]:hover { background-color: #2D3342; color: #FFFFFF !important; }
    .stTabs [aria-selected="true"] {
        background-color: #2979FF !important; color: #FFFFFF !important; border: none;
        box-shadow: 0 4px 15px rgba(41, 121, 255, 0.4);
    }

    [data-testid='stFileUploader'] {
        background-color: rgba(30, 35, 46, 0.6); border: 2px dashed #444C5C; border-radius: 20px;
        padding: 40px 20px; text-align: center; transition: all 0.3s;
    }
    [data-testid='stFileUploader']:hover { border-color: #2979FF; background-color: rgba(41, 121, 255, 0.05); }
    [data-testid='stFileUploader'] section { background-color: transparent !important; }
    [data-testid='stFileUploader'] small { display: none; }

    .info-card {
        background-color: #161920; border-radius: 16px; padding: 20px; margin-bottom: 20px;
        border: 1px solid #2A2F3A; position: relative;
    }
    .card-style { border-left: 6px solid #FF4081; }
    .card-shot  { border-left: 6px solid #FFD740; }
    .card-prompt{ border-left: 6px solid #448AFF; }
    .card-audio { border-left: 6px solid #00E676; }
    .card-ocr   { border-left: 6px solid #FF6E40; }
    .card-cn    { border-left: 6px solid #9C27B0; }
    .card-poster { border-left: 6px solid #00BCD4; }

    .card-header { font-size: 1.1rem; font-weight: 700; margin-bottom: 12px; display: flex; align-items: center; gap: 8px; }
    .pink { color: #FF4081 !important; }
    .yellow { color: #FFD740 !important; }
    .blue { color: #448AFF !important; }
    .green { color: #00E676 !important; }
    .orange { color: #FF6E40 !important; }
    .purple { color: #9C27B0 !important; }
    .cyan { color: #00BCD4 !important; }

    .card-content {
        font-family: 'JetBrains Mono', monospace; font-size: 1rem; line-height: 1.6;
        color: #D1D5DB !important; background: rgba(255,255,255,0.03); padding: 12px; border-radius: 8px;
    }
    img { border-radius: 12px; }
    
    .stDownloadButton button {
        background-color: transparent !important;
        border: 1px solid #444 !important;
        color: #888 !important;
        font-size: 12px;
        padding: 5px 15px;
    }
    .stDownloadButton button:hover {
        border-color: #2979FF !important;
        color: #2979FF !important;
    }
    
    /* ç™»å½•æ¡†æ ·å¼ */
    .login-box {
        background: linear-gradient(135deg, #1a1f2e 0%, #0d1117 100%);
        border: 1px solid #30363d;
        border-radius: 16px;
        padding: 40px;
        max-width: 400px;
        margin: 50px auto;
    }
    .login-title {
        text-align: center;
        font-size: 1.5rem;
        margin-bottom: 30px;
        color: #00BCD4 !important;
    }
</style>
""", unsafe_allow_html=True)

# --- 3. æ ¸å¿ƒé€»è¾‘å‡½æ•° ---

def get_image_base64(image_array):
    img = Image.fromarray(cv2.cvtColor(image_array, cv2.COLOR_BGR2RGB))
    buffer = io.BytesIO()
    img.save(buffer, format="JPEG")
    return base64.b64encode(buffer.getvalue()).decode('utf-8')

def convert_frame_to_bytes(frame_array):
    img = Image.fromarray(cv2.cvtColor(frame_array, cv2.COLOR_BGR2RGB))
    buf = io.BytesIO()
    img.save(buf, format="PNG")
    return buf.getvalue()

def get_frame_at_time(video_path, time_sec=1.5):
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    if fps == 0: fps = 30.0
    frame_id = int(fps * time_sec)
    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_id)
    ret, frame = cap.read()
    cap.release()
    return frame if ret else None

def get_video_dimensions(video_path):
    """è·å–è§†é¢‘å°ºå¯¸"""
    cap = cv2.VideoCapture(video_path)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    cap.release()
    return width, height

def detect_scenes_ignore_subtitles(video_path, threshold=30.0):
    cap = cv2.VideoCapture(video_path)
    frames = []
    timestamps = []
    prev_hist = None
    frame_count = 0
    fps = cap.get(cv2.CAP_PROP_FPS)
    if fps == 0: fps = 30.0 
    while True:
        ret, frame = cap.read()
        if not ret: break
        if frame_count % 15 == 0: 
            height, width, _ = frame.shape
            crop_h = int(height * 0.8) 
            cropped_frame = frame[0:crop_h, :] 
            hsv = cv2.cvtColor(cropped_frame, cv2.COLOR_BGR2HSV)
            hist = cv2.calcHist([hsv], [0, 1], None, [180, 256], [0, 180, 0, 256])
            cv2.normalize(hist, hist, 0, 1, cv2.NORM_MINMAX)
            if prev_hist is None:
                frames.append(frame)
                timestamps.append(frame_count / fps)
                prev_hist = hist
            else:
                score = cv2.compareHist(prev_hist, hist, cv2.HISTCMP_CORREL)
                if (1 - score) > (threshold / 100.0) and (frame_count / fps - timestamps[-1] > 1.5):
                    frames.append(frame)
                    timestamps.append(frame_count / fps)
                    prev_hist = hist
        frame_count += 1
    cap.release()
    return frames, timestamps

def analyze_image_reverse_engineering(image_base64):
    client = OpenAI(api_key=VISION_API_KEY, base_url=VISION_BASE_URL)
    system_prompt = """
    ä½ æ˜¯ä¸€ä½é¡¶çº§çš„ AI ç»˜ç”»æç¤ºè¯å·¥ç¨‹å¸ˆï¼ˆPrompt Engineerï¼‰ï¼Œç²¾é€š Midjourneyã€Stable Diffusion å’Œ Flux çš„æç¤ºè¯é€»è¾‘ã€‚
    è¯·æ·±åº¦å‰–æè¿™å¼ å›¾ç‰‡ï¼Œåæ¨å‡ºèƒ½å®Œç¾è¿˜åŸè¯¥ç”»é¢çš„æç¤ºè¯ã€‚
    
    è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºï¼ˆä¸è¦ Markdownï¼‰ï¼š
    {
        "style": "è¿™é‡Œåˆ—å‡ºæ ¸å¿ƒè‰ºæœ¯é£æ ¼ã€‚ä¾‹å¦‚ï¼šCyberpunk, Ukiyo-e, Oil Painting, 3D Render (Octane), Pixar Style, Matte Painting...",
        "shot": "è¿™é‡Œåˆ—å‡ºé•œå¤´ä¸å…‰å½±ã€‚ä¾‹å¦‚ï¼šWide angle, Telephoto lens, Dutch angle, Volumetric lighting, Rim light, Bokeh...",
        "prompt": "è¿™é‡Œç¼–å†™ä¸€æ®µé«˜è´¨é‡çš„è‹±æ–‡ Promptã€‚å¿…é¡»åŒ…å«ï¼š
                   1. ä¸»ä½“ç»†èŠ‚ï¼ˆäº”å®˜ã€è¡£ç€æè´¨ã€è¡¨æƒ…ï¼‰ã€‚
                   2. ç¯å¢ƒç»†èŠ‚ï¼ˆèƒŒæ™¯å…ƒç´ ã€å¤©æ°”ï¼‰ã€‚
                   3. æŠ€æœ¯å‚æ•°ï¼ˆå¦‚ï¼š8k, photorealistic, masterpiece, highly detailed, unreal engine 5ï¼‰ã€‚
                   è¯·ä½¿ç”¨é€—å·åˆ†éš”çš„å…³é”®è¯å½¢å¼ã€‚"
    }
    """
    try:
        response = client.chat.completions.create(
            model=VISION_MODEL,
            messages=[
                {"role": "user", "content": [
                    {"type": "text", "text": system_prompt},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}}
                ]}
            ],
            max_tokens=800,
        )
        content = response.choices[0].message.content.replace("```json", "").replace("```", "").strip()
        return json.loads(content)
    except Exception as e:
        return {"style": "Error", "shot": "Error", "prompt": str(e)}

def analyze_video_frame_reconstruction(image_base64):
    client = OpenAI(api_key=VISION_API_KEY, base_url=VISION_BASE_URL)
    system_prompt = """
    ä½ æ˜¯ä¸€ä¸ªé¡¶çº§çš„ AI è‰ºæœ¯å¯¼æ¼”å’Œæç¤ºè¯ä¸“å®¶ã€‚
    è¯·æ·±åº¦åˆ†æè¿™å¼ è§†é¢‘æˆªå›¾ï¼Œç›®æ ‡æ˜¯ç”Ÿæˆä¸€æ®µèƒ½è®© Midjourney/Sora å®Œç¾è¿˜åŸç”»é¢ç¥éŸµçš„è‹±æ–‡ Promptã€‚
    
    è¯·ç‰¹åˆ«æ³¨æ„ä»¥ä¸‹ç»†èŠ‚çš„æå–ï¼š
    1. **äººç‰©èº«ä»½ä¸ç‰¹å¾**ï¼šä¸è¦åªè¯´ "Person"ã€‚è¯·ä»”ç»†è§‚å¯Ÿè¡£ç€ï¼ˆå¦‚é•¿è¢ã€æ–—ç¬ ã€ç ´æ—§è¡£ç‰©ï¼‰ï¼Œåˆ¤æ–­æ˜¯å¦ä¸º Monk (åƒ§äºº), Daoist (é“å£«), Wanderer (æµæµªè€…) æˆ– Elder (è€è€…)ã€‚
    2. **æ‘„å½±ä¸è‰ºæœ¯é£æ ¼**ï¼šè¿™æ˜¯å†™å®ç…§ç‰‡ã€CGæ¸²æŸ“è¿˜æ˜¯é»‘ç™½ç”µå½±ï¼Ÿå¦‚æœæ˜¯é»‘ç™½çš„ï¼Œè¯·åŠ ä¸Š "Black and white photography, vintage style, film grain" ç­‰å…³é”®è¯ã€‚
    3. **ç¯å¢ƒä¸æ°›å›´**ï¼šæè¿°å¤©æ°”ï¼ˆé˜´æ²‰ã€è¿·é›¾ï¼‰ã€å…‰å½±ï¼ˆæŸ”å…‰ã€é€†å…‰ï¼‰åŠç”»é¢çš„æƒ…ç»ªï¼ˆå­¤ç‹¬ã€å²è¯—æ„Ÿï¼‰ã€‚
    
    è¯·ä¸¥æ ¼æŒ‰ç…§ JSON æ ¼å¼è¾“å‡ºï¼š
    {
        "cn_desc": "ä¸­æ–‡æ·±åº¦ç”»é¢æè¿°ï¼ˆå¿…é¡»æ˜ç¡®å†™å‡ºäººç‰©èº«ä»½ï¼Œå¦‚ï¼šèƒŒè´Ÿè¡Œå›Šçš„è‹¦è¡Œåƒ§/è€é“å£«ï¼Œä»¥åŠç”»é¢çš„é»‘ç™½å¤å¤è´¨æ„Ÿï¼‰",
        "en_prompt": "High-fidelity English text-to-image prompt. Include keywords for: Subject Identity (e.g., old monk, ascetic), Clothing (traditional robes), Art Style (e.g., 1920s vintage photography, black and white, grainy film), Lighting, and Atmosphere."
    }
    ä¸è¦è¾“å‡º Markdown æ ‡è®°ã€‚
    """
    try:
        response = client.chat.completions.create(
            model=VISION_MODEL,
            messages=[
                {"role": "user", "content": [
                    {"type": "text", "text": system_prompt},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}}
                ]}
            ],
            max_tokens=800,
        )
        content = response.choices[0].message.content.replace("```json", "").replace("```", "").strip()
        return json.loads(content)
    except Exception as e:
        return {"cn_desc": "è§£æå¤±è´¥", "en_prompt": str(e)}

def analyze_ocr_text(image_base64):
    client = OpenAI(api_key=VISION_API_KEY, base_url=VISION_BASE_URL)
    system_prompt = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ OCR æ–‡å­—è¯†åˆ«åŠ©æ‰‹ã€‚è¯·è¯†åˆ«ç”»é¢ä¸­å‡ºç°çš„æ‰€æœ‰ã€å›ºå®šä¸­æ–‡æ–‡å­—ã€‘ï¼Œå¿½ç•¥åº•éƒ¨çš„å³æ—¶å­—å¹•ã€‚ç›´æ¥è¾“å‡ºå†…å®¹ã€‚"
    try:
        response = client.chat.completions.create(
            model=VISION_MODEL,
            messages=[
                {"role": "user", "content": [{"type": "text", "text": system_prompt}, {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}}]}
            ], max_tokens=500,
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"OCR Error: {str(e)}"

def transcribe_audio_api(video_path):
    try:
        with tempfile.NamedTemporaryFile(suffix=".mp3", delete=False) as temp_audio:
            audio_path = temp_audio.name
        video = VideoFileClip(video_path)
        video.audio.write_audiofile(audio_path, codec='mp3', logger=None, ffmpeg_params=["-ac", "1"])
        video.close()
        client = OpenAI(api_key=AUDIO_API_KEY, base_url=AUDIO_BASE_URL)
        with open(audio_path, "rb") as audio_file:
            transcript = client.audio.transcriptions.create(model=AUDIO_MODEL, file=audio_file, response_format="text")
        os.remove(audio_path)
        if isinstance(transcript, str):
            try:
                data = json.loads(transcript)
                if "text" in data: return data["text"]
            except: pass
            return transcript
        return transcript.text
    except Exception as e:
        return f"Audio Error: {str(e)}"

# --- å¤§å­—æŠ¥ç”Ÿæˆå‡½æ•° ---

def load_font(size, weight="Regular"):
    """åŠ è½½æ€æºé»‘ä½“ï¼ˆä» Google Fonts CDN æˆ–æœ¬åœ°ï¼‰"""
    # å°è¯•åŠ è½½æœ¬åœ°å­—ä½“æ–‡ä»¶
    font_paths = [
        "NotoSansSC-Bold.ttf",
        "NotoSansSC-Regular.ttf", 
        "/usr/share/fonts/truetype/noto/NotoSansCJK-Bold.ttc",
        "/usr/share/fonts/opentype/noto/NotoSansCJK-Bold.ttc",
    ]
    
    for path in font_paths:
        if os.path.exists(path):
            try:
                return ImageFont.truetype(path, size)
            except:
                continue
    
    # å¦‚æœæ²¡æœ‰æœ¬åœ°å­—ä½“ï¼Œå°è¯•ä¸‹è½½
    try:
        import urllib.request
        font_url = "https://github.com/googlefonts/noto-cjk/raw/main/Sans/OTF/SimplifiedChinese/NotoSansSC-Bold.otf"
        font_path = "/tmp/NotoSansSC-Bold.otf"
        if not os.path.exists(font_path):
            urllib.request.urlretrieve(font_url, font_path)
        return ImageFont.truetype(font_path, size)
    except:
        # æœ€åä½¿ç”¨é»˜è®¤å­—ä½“
        return ImageFont.load_default()

def generate_poster_v1(width, height, line1, line2, line3):
    """
    V1 æ ·å¼ï¼šæ ‡å‡†å±…ä¸­å¸ƒå±€
    - æ ‡é¢˜ï¼šå¤§å·é»„è‰²
    - å‰¯æ ‡é¢˜ï¼šä¸­å·ç™½è‰²
    - è¯„è®ºï¼šä¸­å·é»„è‰²
    """
    img = Image.new('RGBA', (width, height), (0, 0, 0, 0))
    draw = ImageDraw.Draw(img)
    
    # å­—ä½“å¤§å°ï¼ˆæ ¹æ®è§†é¢‘å®½åº¦è‡ªé€‚åº”ï¼‰
    title_size = int(width * 0.08)
    subtitle_size = int(width * 0.045)
    comment_size = int(width * 0.05)
    
    font_title = load_font(title_size)
    font_subtitle = load_font(subtitle_size)
    font_comment = load_font(comment_size)
    
    # é¢œè‰²
    yellow = (255, 255, 0, 255)
    white = (255, 255, 255, 255)
    
    # è®¡ç®—ä½ç½®
    margin_top = int(height * 0.05)
    line_spacing = int(height * 0.02)
    
    # ç¬¬1è¡Œï¼šé»„è‰²å¤§æ ‡é¢˜
    bbox1 = draw.textbbox((0, 0), line1, font=font_title)
    x1 = (width - (bbox1[2] - bbox1[0])) // 2
    y1 = margin_top
    draw.text((x1, y1), line1, font=font_title, fill=yellow)
    
    # ç¬¬2è¡Œï¼šç™½è‰²å‰¯æ ‡é¢˜
    bbox2 = draw.textbbox((0, 0), line2, font=font_subtitle)
    x2 = (width - (bbox2[2] - bbox2[0])) // 2
    y2 = y1 + (bbox1[3] - bbox1[1]) + line_spacing
    draw.text((x2, y2), line2, font=font_subtitle, fill=white)
    
    # ç¬¬3è¡Œï¼šé»„è‰²è¯„è®º
    bbox3 = draw.textbbox((0, 0), line3, font=font_comment)
    x3 = (width - (bbox3[2] - bbox3[0])) // 2
    y3 = y2 + (bbox2[3] - bbox2[1]) + line_spacing * 1.5
    draw.text((x3, y3), line3, font=font_comment, fill=yellow)
    
    return img

def generate_poster_v2(width, height, line1, line2, line3):
    """
    V2 æ ·å¼ï¼šå¤§è¡Œè· + è¾ƒå°å­—ä½“
    - æ•´ä½“æ›´èˆ’æœ—
    - å‰¯æ ‡é¢˜ç”¨æµ…ç°è‰²
    """
    img = Image.new('RGBA', (width, height), (0, 0, 0, 0))
    draw = ImageDraw.Draw(img)
    
    # å­—ä½“å¤§å°ï¼ˆæ¯”V1å°ï¼‰
    title_size = int(width * 0.07)
    subtitle_size = int(width * 0.038)
    comment_size = int(width * 0.042)
    
    font_title = load_font(title_size)
    font_subtitle = load_font(subtitle_size)
    font_comment = load_font(comment_size)
    
    # é¢œè‰²
    yellow = (255, 220, 0, 255)  # åæš–é»„
    light_gray = (200, 200, 200, 255)
    orange_yellow = (255, 180, 0, 255)
    
    # è®¡ç®—ä½ç½®ï¼ˆæ›´å¤§çš„è¾¹è·å’Œè¡Œè·ï¼‰
    margin_top = int(height * 0.06)
    line_spacing = int(height * 0.035)
    
    # ç¬¬1è¡Œ
    bbox1 = draw.textbbox((0, 0), line1, font=font_title)
    x1 = (width - (bbox1[2] - bbox1[0])) // 2
    y1 = margin_top
    draw.text((x1, y1), line1, font=font_title, fill=yellow)
    
    # ç¬¬2è¡Œ
    bbox2 = draw.textbbox((0, 0), line2, font=font_subtitle)
    x2 = (width - (bbox2[2] - bbox2[0])) // 2
    y2 = y1 + (bbox1[3] - bbox1[1]) + line_spacing
    draw.text((x2, y2), line2, font=font_subtitle, fill=light_gray)
    
    # ç¬¬3è¡Œ
    bbox3 = draw.textbbox((0, 0), line3, font=font_comment)
    x3 = (width - (bbox3[2] - bbox3[0])) // 2
    y3 = y2 + (bbox2[3] - bbox2[1]) + line_spacing * 2
    draw.text((x3, y3), line3, font=font_comment, fill=orange_yellow)
    
    return img

def generate_poster_v3(width, height, line1, line2, line3):
    """
    V3 æ ·å¼ï¼šè¶…å¤§æ ‡é¢˜ + ç´§å‡‘å¸ƒå±€
    - æ ‡é¢˜ç‰¹åˆ«å¤§
    - æ•´ä½“æ›´ç´§å‡‘æœ‰å†²å‡»åŠ›
    """
    img = Image.new('RGBA', (width, height), (0, 0, 0, 0))
    draw = ImageDraw.Draw(img)
    
    # å­—ä½“å¤§å°ï¼ˆæ ‡é¢˜è¶…å¤§ï¼‰
    title_size = int(width * 0.10)
    subtitle_size = int(width * 0.04)
    comment_size = int(width * 0.055)
    
    font_title = load_font(title_size)
    font_subtitle = load_font(subtitle_size)
    font_comment = load_font(comment_size)
    
    # é¢œè‰²ï¼ˆé«˜å¯¹æ¯”åº¦ï¼‰
    bright_yellow = (255, 255, 50, 255)
    white = (255, 255, 255, 255)
    gold = (255, 215, 0, 255)
    
    # è®¡ç®—ä½ç½®ï¼ˆç´§å‡‘ï¼‰
    margin_top = int(height * 0.04)
    line_spacing = int(height * 0.015)
    
    # ç¬¬1è¡Œ
    bbox1 = draw.textbbox((0, 0), line1, font=font_title)
    x1 = (width - (bbox1[2] - bbox1[0])) // 2
    y1 = margin_top
    draw.text((x1, y1), line1, font=font_title, fill=bright_yellow)
    
    # ç¬¬2è¡Œ
    bbox2 = draw.textbbox((0, 0), line2, font=font_subtitle)
    x2 = (width - (bbox2[2] - bbox2[0])) // 2
    y2 = y1 + (bbox1[3] - bbox1[1]) + line_spacing
    draw.text((x2, y2), line2, font=font_subtitle, fill=white)
    
    # ç¬¬3è¡Œ
    bbox3 = draw.textbbox((0, 0), line3, font=font_comment)
    x3 = (width - (bbox3[2] - bbox3[0])) // 2
    y3 = y2 + (bbox2[3] - bbox2[1]) + line_spacing
    draw.text((x3, y3), line3, font=font_comment, fill=gold)
    
    return img

def process_video_with_effects(video_path, mirror=False, high_saturation=False):
    """
    å¤„ç†è§†é¢‘ï¼šé•œåƒ / é«˜é¥±å’Œåº¦é«˜äº®åº¦
    è¿”å›å¤„ç†åçš„è§†é¢‘è·¯å¾„
    """
    if not mirror and not high_saturation:
        return video_path
    
    output_path = tempfile.NamedTemporaryFile(suffix=".mp4", delete=False).name
    
    filters = []
    if mirror:
        filters.append("hflip")
    if high_saturation:
        filters.append("eq=saturation=1.5:brightness=0.1")
    
    filter_str = ",".join(filters)
    
    cmd = [
        "ffmpeg", "-y",
        "-i", video_path,
        "-vf", filter_str,
        "-c:a", "copy",
        output_path
    ]
    
    try:
        subprocess.run(cmd, check=True, capture_output=True)
        return output_path
    except subprocess.CalledProcessError as e:
        st.error(f"è§†é¢‘å¤„ç†å¤±è´¥: {e}")
        return video_path

def overlay_png_on_video(video_path, png_image, output_path):
    """
    ä½¿ç”¨ FFmpeg å°† PNG å åŠ åˆ°è§†é¢‘ä¸Š
    """
    # ä¿å­˜ PNG åˆ°ä¸´æ—¶æ–‡ä»¶
    png_temp = tempfile.NamedTemporaryFile(suffix=".png", delete=False)
    png_image.save(png_temp.name, "PNG")
    
    cmd = [
        "ffmpeg", "-y",
        "-i", video_path,
        "-i", png_temp.name,
        "-filter_complex", "[0:v][1:v]overlay=0:0:format=auto",
        "-c:a", "copy",
        output_path
    ]
    
    try:
        subprocess.run(cmd, check=True, capture_output=True)
        os.remove(png_temp.name)
        return True
    except subprocess.CalledProcessError as e:
        st.error(f"å åŠ å¤±è´¥: {e.stderr.decode()}")
        os.remove(png_temp.name)
        return False

def generate_all_videos(video_path, line1, line2, line3, use_mirror, use_saturation):
    """
    ç”Ÿæˆæ‰€æœ‰ç‰ˆæœ¬çš„è§†é¢‘
    è¿”å›: [(æ–‡ä»¶å, æ–‡ä»¶è·¯å¾„), ...]
    """
    results = []
    width, height = get_video_dimensions(video_path)
    
    # ç”Ÿæˆä¸‰ä¸ªç‰ˆæœ¬çš„ PNG
    posters = {
        "V1": generate_poster_v1(width, height, line1, line2, line3),
        "V2": generate_poster_v2(width, height, line1, line2, line3),
        "V3": generate_poster_v3(width, height, line1, line2, line3),
    }
    
    # ç¡®å®šè¦å¤„ç†çš„æ•ˆæœç»„åˆ
    effect_combinations = []
    
    if not use_mirror and not use_saturation:
        # æ— ç‰¹æ•ˆï¼šåªç”ŸæˆåŸç‰ˆ
        effect_combinations.append(("åŸç‰ˆ", video_path))
    else:
        if use_mirror:
            mirror_video = process_video_with_effects(video_path, mirror=True, high_saturation=False)
            effect_combinations.append(("é•œåƒ", mirror_video))
        if use_saturation:
            sat_video = process_video_with_effects(video_path, mirror=False, high_saturation=True)
            effect_combinations.append(("é«˜é¥±å’Œ", sat_video))
    
    # ä¸ºæ¯ä¸ªæ•ˆæœç»„åˆç”Ÿæˆ V1/V2/V3
    for effect_name, processed_video in effect_combinations:
        for version, poster_img in posters.items():
            output_file = tempfile.NamedTemporaryFile(suffix=".mp4", delete=False)
            output_path = output_file.name
            
            if overlay_png_on_video(processed_video, poster_img, output_path):
                if effect_name == "åŸç‰ˆ":
                    filename = f"å¤§å­—æŠ¥_{version}.mp4"
                else:
                    filename = f"å¤§å­—æŠ¥_{effect_name}_{version}.mp4"
                results.append((filename, output_path))
    
    return results

# --- 4. ç•Œé¢æ¸²æŸ“ ---

st.markdown("<h1>è§†å¬è¯­è¨€åˆ†æå·¥ä½œç«™</h1>", unsafe_allow_html=True)
st.markdown("<div class='subtitle'>Visual Intelligence Analysis Workstation</div>", unsafe_allow_html=True)

# Tab å¯¼èˆªåŒº
tab1, tab2, tab3, tab4, tab5 = st.tabs(["å›¾ç”Ÿæ–‡åæ¨", "è§†é¢‘æ‹†è§£", "å£æ’­æ‰’å–", "æ–‡å­—æå–", "ğŸ”’ å¤§å­—æŠ¥ç”Ÿæˆ"])

# === Tab 1: å›¾ç”Ÿæ–‡ ===
with tab1:
    st.markdown("<div style='text-align:center; color:#888; margin-bottom:10px;'>AI åæ¨é£æ ¼ã€é•œå¤´è¯­è¨€åŠç”Ÿå›¾æç¤ºè¯</div>", unsafe_allow_html=True)
    
    c1, c2, c3 = st.columns([1, 2, 1])
    with c2:
        uploaded_img = st.file_uploader(" ", type=["jpg", "png"], key="img_up")

    if uploaded_img:
        with st.spinner("AI è§†è§‰å¼•æ“æ­£åœ¨è§£æ..."):
            image = Image.open(uploaded_img)
            buffered = io.BytesIO()
            image.save(buffered, format="JPEG")
            img_b64 = base64.b64encode(buffered.getvalue()).decode('utf-8')
            result = analyze_image_reverse_engineering(img_b64)
            
            st.write("")
            r1, r2 = st.columns([1, 2])
            with r1:
                st.image(uploaded_img, caption="åŸå§‹å›¾ç‰‡", use_container_width=True)
            with r2:
                st.markdown(f"""
                <div class="info-card card-style">
                    <div class="card-header pink">ğŸ¨ é£æ ¼æç¤ºè¯ (Style)</div>
                    <div class="card-content">{result.get('style', 'N/A')}</div>
                </div>
                <div class="info-card card-shot">
                    <div class="card-header yellow">ğŸ“· é•œå¤´ä¸æ™¯åˆ« (Shot)</div>
                    <div class="card-content">{result.get('shot', 'N/A')}</div>
                </div>
                <div class="info-card card-prompt">
                    <div class="card-header blue">âœ¨ AI ç”Ÿå›¾æç¤ºè¯ (Prompt)</div>
                    <div class="card-content" style="user-select: all;">{result.get('prompt', 'N/A')}</div>
                </div>
                """, unsafe_allow_html=True)

# === Tab 2: è§†é¢‘æ‹†è§£ ===
with tab2:
    st.markdown("<div style='text-align:center; color:#888; margin-bottom:10px;'>ç”Ÿæˆç”»é¢å¸§åŒè¯­æç¤ºè¯ (é€‚ç”¨äºå³æ¢¦/NanoBananaç”»é¢è¿˜åŸ)</div>", unsafe_allow_html=True)
    
    t2_c1, t2_c2, t2_c3 = st.columns([1, 2, 1])
    with t2_c2:
        v_file = st.file_uploader(" ", type=["mp4", "mov"], key="v_up")
        threshold = st.slider("åˆ‡é•œçµæ•åº¦", 10, 60, 25)

    if v_file:
        tfile = tempfile.NamedTemporaryFile(delete=False)
        tfile.write(v_file.read())
        
        with st.status("æ­£åœ¨é€å¸§åˆ†æä¸ç”Ÿæˆæç¤ºè¯...", expanded=True) as status:
            frames, tstamps = detect_scenes_ignore_subtitles(tfile.name, threshold)
            st.write(f"æ£€æµ‹åˆ° {len(frames)} ä¸ªå…³é”®é•œå¤´ï¼Œæ­£åœ¨ç”Ÿæˆè¿˜åŸ Prompt...")
            
            res_container = st.container()
            for i, (frm, ts) in enumerate(zip(frames, tstamps)):
                b64 = get_image_base64(frm)
                res = analyze_video_frame_reconstruction(b64)
                
                with res_container:
                    res_c1, res_c2 = st.columns([2, 3])
                    
                    with res_c1:
                        st.image(frm, channels="BGR", use_container_width=True)
                        img_bytes = convert_frame_to_bytes(frm)
                        st.download_button(
                            label="ğŸ“¥ ä¸‹è½½è¯¥å¸§",
                            data=img_bytes,
                            file_name=f"frame_{ts:.2f}.png",
                            mime="image/png",
                            key=f"dl_{ts}"
                        )
                        st.caption(f"â±ï¸ æ—¶é—´ç‚¹: {ts:.2f}s")
                        
                    with res_c2:
                        st.markdown(f"""
                        <div class="info-card card-cn" style="margin-bottom:10px;">
                            <div class="card-header purple">ğŸ“ ä¸­æ–‡ç”»é¢æè¿°</div>
                            <div class="card-content">{res.get('cn_desc', '...')}</div>
                        </div>
                        <div class="info-card card-prompt">
                            <div class="card-header blue">âœ¨ ç”»é¢è¿˜åŸ Prompt (Image Gen)</div>
                            <div class="card-content" style="user-select: all;">{res.get('en_prompt', '...')}</div>
                        </div>
                        """, unsafe_allow_html=True)
                    st.divider()
            status.update(label="âœ… åˆ†æå®Œæˆ", state="complete", expanded=False)

# === Tab 3: å£æ’­æ‰’å– ===
with tab3:
    st.markdown("<div style='text-align:center; color:#888; margin-bottom:10px;'>æå–è¯­éŸ³ï¼Œè½¬æ¢ä¸ºé€å­—ç¨¿</div>", unsafe_allow_html=True)
    
    t3_c1, t3_c2, t3_c3 = st.columns([1, 2, 1])
    with t3_c2:
        a_file = st.file_uploader(" ", type=["mp4", "mp3", "wav"], key="a_up")
    
    if a_file:
        tfile_a = tempfile.NamedTemporaryFile(delete=False)
        tfile_a.write(a_file.read())
        with st.spinner("AI å¬å†™ä¸­..."):
            txt = transcribe_audio_api(tfile_a.name)
            
            r3_c1, r3_c2, r3_c3 = st.columns([1, 6, 1])
            with r3_c2:
                st.audio(a_file)
                st.markdown(f"""
                <div class="info-card card-audio">
                    <div class="card-header green">ğŸ™ï¸ é€å­—ç¨¿ (Transcript)</div>
                    <div class="card-content" style="user-select: all;">{txt}</div>
                </div>
                """, unsafe_allow_html=True)

# === Tab 4: æ–‡å­—æå– ===
with tab4:
    st.markdown("<div style='text-align:center; color:#888; margin-bottom:10px;'>è¯†åˆ«å¤§å­—æŠ¥ã€åŒ…è£…æ–‡å­—åŠå…³é”®ä¿¡æ¯</div>", unsafe_allow_html=True)
    
    t4_c1, t4_c2, t4_c3 = st.columns([1, 2, 1])
    with t4_c2:
        ocr_file = st.file_uploader(" ", type=["mp4", "mov"], key="ocr_up")
    
    if ocr_file:
        tfile_ocr = tempfile.NamedTemporaryFile(delete=False)
        tfile_ocr.write(ocr_file.read())
        frame = get_frame_at_time(tfile_ocr.name, time_sec=1.5)
        
        if frame is not None:
            with st.spinner("OCR è¯†åˆ«ä¸­..."):
                b64 = get_image_base64(frame)
                ocr_text = analyze_ocr_text(b64)
                
                ocr_c1, ocr_c2 = st.columns([1, 1])
                with ocr_c1:
                    st.image(frame, channels="BGR", caption="è¯†åˆ«å¸§", use_container_width=True)
                with ocr_c2:
                    st.markdown(f"""
                    <div class="info-card card-ocr">
                        <div class="card-header orange">ğŸ”  æå–ç»“æœ (OCR)</div>
                        <div class="card-content" style="white-space: pre-line; user-select: all;">{ocr_text}</div>
                    </div>
                    """, unsafe_allow_html=True)

# === Tab 5: å¤§å­—æŠ¥ç”Ÿæˆï¼ˆéœ€ç™»å½•ï¼‰ ===
with tab5:
    st.markdown("<div style='text-align:center; color:#888; margin-bottom:10px;'>ğŸ” å›¢é˜Ÿä¸“ç”¨åŠŸèƒ½ - è‡ªåŠ¨ç”Ÿæˆå¤§å­—æŠ¥è§†é¢‘</div>", unsafe_allow_html=True)
    
    # æ£€æŸ¥ç™»å½•çŠ¶æ€
    if not check_login():
        # æ˜¾ç¤ºç™»å½•æ¡†
        login_c1, login_c2, login_c3 = st.columns([1, 1.5, 1])
        with login_c2:
            st.markdown("""
            <div style="text-align:center; margin: 30px 0;">
                <span style="font-size: 3rem;">ğŸ”</span>
                <h3 style="margin-top: 10px;">å›¢é˜Ÿæˆå‘˜ç™»å½•</h3>
            </div>
            """, unsafe_allow_html=True)
            
            username = st.text_input("è´¦å·", placeholder="è¯·è¾“å…¥è´¦å·")
            password = st.text_input("å¯†ç ", type="password", placeholder="è¯·è¾“å…¥å¯†ç ")
            
            if st.button("ç™» å½•", use_container_width=True):
                if username in USERS and USERS[username] == password:
                    st.session_state["logged_in"] = True
                    st.session_state["username"] = username
                    st.success(f"âœ… æ¬¢è¿å›æ¥ï¼Œ{username}ï¼")
                    st.rerun()
                else:
                    st.error("âŒ è´¦å·æˆ–å¯†ç é”™è¯¯")
    else:
        # å·²ç™»å½•ï¼Œæ˜¾ç¤ºåŠŸèƒ½ç•Œé¢
        current_user = get_current_user()
        
        # é¡¶éƒ¨æ˜¾ç¤ºç”¨æˆ·ä¿¡æ¯å’Œé€€å‡ºæŒ‰é’®
        user_col1, user_col2 = st.columns([6, 1])
        with user_col1:
            st.markdown(f"<div style='color:#00BCD4;'>ğŸ‘¤ å½“å‰ç”¨æˆ·: <b>{current_user}</b></div>", unsafe_allow_html=True)
        with user_col2:
            if st.button("é€€å‡ºç™»å½•"):
                st.session_state["logged_in"] = False
                st.session_state["username"] = None
                st.rerun()
        
        st.divider()
        
        # ä¸»åŠŸèƒ½åŒº
        main_c1, main_c2 = st.columns([1, 1])
        
        with main_c1:
            st.markdown("### ğŸ“¤ ä¸Šä¼ è§†é¢‘")
            poster_video = st.file_uploader("æ‹–å…¥ MP4 æ–‡ä»¶", type=["mp4", "mov"], key="poster_video")
            
            if poster_video:
                st.video(poster_video)
        
        with main_c2:
            st.markdown("### âœï¸ è¾“å…¥æ–‡å­—")
            line1 = st.text_input("ç¬¬1è¡Œï¼ˆé»„è‰²å¤§æ ‡é¢˜ï¼‰", value="ä¸‰å›½&æ¨¡æ‹Ÿ&ç»è¥", placeholder="ä¾‹ï¼šä¸‰å›½&æ¨¡æ‹Ÿ&ç»è¥")
            line2 = st.text_input("ç¬¬2è¡Œï¼ˆç™½è‰²å‰¯æ ‡é¢˜ï¼‰", value="ä¸€æ¬¾ä»¥æ¨¡æ‹Ÿç»è¥ä¸ºæ ¸å¿ƒçš„ç°ä»£ä¸‰å›½æ‰‹æ¸¸", placeholder="ä¾‹ï¼šä¸€æ¬¾ä»¥æ¨¡æ‹Ÿç»è¥ä¸ºæ ¸å¿ƒçš„...")
            line3 = st.text_input("ç¬¬3è¡Œï¼ˆé»„è‰²è¯„è®ºï¼‰", value="ç©å®¶ï¼šç©äº†ä¸‰å¤©è¿˜åœ¨æ–°æ‰‹æ‘ç»è¥æœ¨æå‚", placeholder="ä¾‹ï¼šç©å®¶ï¼šç©äº†ä¸‰å¤©...")
            
            st.markdown("### âš™ï¸ ç‰¹æ•ˆé€‰é¡¹")
            col_opt1, col_opt2 = st.columns(2)
            with col_opt1:
                use_mirror = st.checkbox("ğŸ”„ é•œåƒå¤„ç†", help="æ°´å¹³ç¿»è½¬è§†é¢‘")
            with col_opt2:
                use_saturation = st.checkbox("ğŸŒˆ é«˜é¥±å’Œé«˜äº®åº¦", help="æå‡ç”»é¢é²œè‰³åº¦")
        
        st.divider()
        
        # é¢„è§ˆåŒºåŸŸ
        if poster_video and line1:
            st.markdown("### ğŸ‘ï¸ æ ·å¼é¢„è§ˆ")
            
            # ä¸´æ—¶ä¿å­˜è§†é¢‘è·å–å°ºå¯¸
            temp_video = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
            temp_video.write(poster_video.read())
            poster_video.seek(0)  # é‡ç½®è¯»å–ä½ç½®
            
            width, height = get_video_dimensions(temp_video.name)
            
            # ç”Ÿæˆé¢„è§ˆå›¾
            preview_cols = st.columns(3)
            
            posters = [
                ("V1 æ ‡å‡†", generate_poster_v1(width, height, line1, line2, line3)),
                ("V2 èˆ’æœ—", generate_poster_v2(width, height, line1, line2, line3)),
                ("V3 å†²å‡»", generate_poster_v3(width, height, line1, line2, line3)),
            ]
            
            # è·å–è§†é¢‘ç¬¬ä¸€å¸§ä½œä¸ºèƒŒæ™¯
            bg_frame = get_frame_at_time(temp_video.name, 0.5)
            
            for i, (name, poster) in enumerate(posters):
                with preview_cols[i]:
                    # åˆæˆé¢„è§ˆå›¾
                    if bg_frame is not None:
                        bg_img = Image.fromarray(cv2.cvtColor(bg_frame, cv2.COLOR_BGR2RGB)).convert("RGBA")
                        bg_img = bg_img.resize((width, height))
                        preview = Image.alpha_composite(bg_img, poster)
                        st.image(preview, caption=name, use_container_width=True)
                    else:
                        # çº¯é»‘èƒŒæ™¯é¢„è§ˆ
                        black_bg = Image.new('RGBA', (width, height), (0, 0, 0, 255))
                        preview = Image.alpha_composite(black_bg, poster)
                        st.image(preview, caption=name, use_container_width=True)
        
        st.divider()
        
        # ç”ŸæˆæŒ‰é’®
        gen_c1, gen_c2, gen_c3 = st.columns([1, 2, 1])
        with gen_c2:
            generate_btn = st.button("ğŸš€ ç”Ÿæˆå¤§å­—æŠ¥è§†é¢‘", use_container_width=True, type="primary")
        
        if generate_btn and poster_video:
            # è®°å½•ä½¿ç”¨æ—¥å¿—
            options_str = []
            if use_mirror: options_str.append("é•œåƒ")
            if use_saturation: options_str.append("é«˜é¥±å’Œ")
            log_usage(current_user, "å¤§å­—æŠ¥ç”Ÿæˆ", ", ".join(options_str) if options_str else "æ— ç‰¹æ•ˆ")
            
            with st.status("æ­£åœ¨ç”Ÿæˆè§†é¢‘...", expanded=True) as status:
                # ä¿å­˜ä¸Šä¼ çš„è§†é¢‘
                temp_input = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
                poster_video.seek(0)
                temp_input.write(poster_video.read())
                temp_input.close()
                
                st.write("ğŸ“ è¯»å–è§†é¢‘ä¿¡æ¯...")
                
                st.write("ğŸ¨ ç”Ÿæˆå¤§å­—æŠ¥ PNG...")
                
                st.write("ğŸ¬ åˆæˆè§†é¢‘...")
                
                results = generate_all_videos(
                    temp_input.name, 
                    line1, line2, line3,
                    use_mirror, use_saturation
                )
                
                status.update(label=f"âœ… ç”Ÿæˆå®Œæˆï¼å…± {len(results)} ä¸ªè§†é¢‘", state="complete")
            
            # æ˜¾ç¤ºä¸‹è½½æŒ‰é’®
            if results:
                st.markdown("### ğŸ“¥ ä¸‹è½½ç”Ÿæˆçš„è§†é¢‘")
                
                download_cols = st.columns(3)
                for i, (filename, filepath) in enumerate(results):
                    with download_cols[i % 3]:
                        with open(filepath, "rb") as f:
                            st.download_button(
                                label=f"ğŸ“¥ {filename}",
                                data=f.read(),
                                file_name=filename,
                                mime="video/mp4",
                                key=f"dl_poster_{i}"
                            )
                
                # æä¾›æ‰“åŒ…ä¸‹è½½
                if len(results) > 1:
                    st.divider()
                    zip_buffer = io.BytesIO()
                    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zf:
                        for filename, filepath in results:
                            zf.write(filepath, filename)
                    
                    st.download_button(
                        label="ğŸ“¦ æ‰“åŒ…ä¸‹è½½å…¨éƒ¨",
                        data=zip_buffer.getvalue(),
                        file_name="å¤§å­—æŠ¥è§†é¢‘åˆé›†.zip",
                        mime="application/zip",
                        use_container_width=True
                    )
                
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                for _, filepath in results:
                    try:
                        os.remove(filepath)
                    except:
                        pass
