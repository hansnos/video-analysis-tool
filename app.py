import streamlit as st
import cv2
import numpy as np
import base64
from openai import OpenAI
import tempfile
import os
from PIL import Image, ImageDraw, ImageFont
import io
import json
from datetime import datetime
import zipfile
import urllib.request

# moviepy å¤„ç†è§†é¢‘
from moviepy.editor import VideoFileClip, ImageClip, CompositeVideoClip

# --- 1. é…ç½®ä¸å¯†é’¥åŠ è½½ ---
st.set_page_config(
    page_title="è§†å¬è¯­è¨€åˆ†æå·¥ä½œç«™", 
    page_icon="ğŸ¬", 
    layout="wide",
    initial_sidebar_state="collapsed"
)

# API é…ç½®
try:
    VISION_API_KEY = st.secrets["vision"]["api_key"]
    VISION_BASE_URL = st.secrets["vision"]["base_url"]
    VISION_MODEL = st.secrets["vision"]["model"]
    
    AUDIO_API_KEY = st.secrets["audio"]["api_key"]
    AUDIO_BASE_URL = st.secrets["audio"]["base_url"]
    AUDIO_MODEL = st.secrets["audio"]["model"]
except Exception as e:
    st.error(f"âš ï¸ é…ç½®ç¼ºå¤±: {e}ã€‚è¯·æ£€æŸ¥ secrets.toml")
    st.stop()

# Google Sheets é…ç½®ï¼ˆå¯é€‰ï¼‰
try:
    GSHEET_CREDENTIALS = st.secrets["gsheet"]["credentials"]
    GSHEET_URL = st.secrets["gsheet"]["sheet_url"]
    GSHEET_ENABLED = True
except:
    GSHEET_ENABLED = False

# --- ç”¨æˆ·è´¦å·ç³»ç»Ÿ ---
USERS = {
    "Baihe123": "Hengxing666",
    "Shujun123": "Hengxing666",
    "Hans123": "Hengxing666",
    "Heixin123": "Hengxing666",
}

def check_login():
    return st.session_state.get("logged_in", False)

def get_current_user():
    return st.session_state.get("username", None)

def log_usage(username, feature, options=""):
    if not GSHEET_ENABLED:
        return
    try:
        import gspread
        from google.oauth2.service_account import Credentials
        scopes = ["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"]
        creds_dict = json.loads(GSHEET_CREDENTIALS)
        credentials = Credentials.from_service_account_info(creds_dict, scopes=scopes)
        gc = gspread.authorize(credentials)
        sheet = gc.open_by_url(GSHEET_URL).sheet1
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        sheet.append_row([timestamp, username, feature, options])
    except Exception as e:
        pass

# --- 2. æ ·å¼ ---
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@400;500;700;900&display=swap');

    .stApp { background-color: #0B0E14; font-family: 'Noto Sans SC', sans-serif; }
    h1, h2, h3, p, div, span, label { color: #FFFFFF !important; }
    .stMarkdown p { color: #B0B6BE !important; }

    h1 {
        font-size: 2.8rem !important; font-weight: 900 !important; text-align: center;
        margin-top: 20px; margin-bottom: 10px; letter-spacing: 2px;
        text-shadow: 0 0 20px rgba(41, 121, 255, 0.3);
    }
    .subtitle { text-align: center; color: #8E95A3 !important; font-size: 1rem; margin-bottom: 40px; }

    .stTabs [data-baseweb="tab-list"] {
        gap: 8px; background-color: transparent; border-bottom: none !important;
        display: flex; justify-content: center; flex-wrap: nowrap; margin-bottom: 30px;
    }
    .stTabs [data-baseweb="tab"] {
        height: 44px; border-radius: 22px; background-color: #1E232E; color: #B0B6BE !important;
        border: 1px solid #2D3342; font-size: 14px; font-weight: 500; padding: 0 30px;
        transition: all 0.2s;
    }
    .stTabs [data-baseweb="tab"]:hover { background-color: #2D3342; color: #FFFFFF !important; }
    .stTabs [aria-selected="true"] {
        background-color: #2979FF !important; color: #FFFFFF !important; border: none;
        box-shadow: 0 4px 15px rgba(41, 121, 255, 0.4);
    }

    [data-testid='stFileUploader'] {
        background-color: rgba(30, 35, 46, 0.6); border: 2px dashed #444C5C; border-radius: 20px;
        padding: 40px 20px; text-align: center; transition: all 0.3s;
    }
    [data-testid='stFileUploader']:hover { border-color: #2979FF; background-color: rgba(41, 121, 255, 0.05); }
    [data-testid='stFileUploader'] section { background-color: transparent !important; }
    [data-testid='stFileUploader'] small { display: none; }

    .info-card {
        background-color: #161920; border-radius: 16px; padding: 20px; margin-bottom: 20px;
        border: 1px solid #2A2F3A; position: relative;
    }
    .card-style { border-left: 6px solid #FF4081; }
    .card-shot  { border-left: 6px solid #FFD740; }
    .card-prompt{ border-left: 6px solid #448AFF; }
    .card-audio { border-left: 6px solid #00E676; }
    .card-cn    { border-left: 6px solid #9C27B0; }
    .card-poster { border-left: 6px solid #00BCD4; }

    .card-header { font-size: 1.1rem; font-weight: 700; margin-bottom: 12px; display: flex; align-items: center; gap: 8px; }
    .pink { color: #FF4081 !important; }
    .yellow { color: #FFD740 !important; }
    .blue { color: #448AFF !important; }
    .green { color: #00E676 !important; }
    .purple { color: #9C27B0 !important; }
    .cyan { color: #00BCD4 !important; }

    .card-content {
        font-family: 'JetBrains Mono', monospace; font-size: 1rem; line-height: 1.6;
        color: #D1D5DB !important; background: rgba(255,255,255,0.03); padding: 12px; border-radius: 8px;
    }
    img { border-radius: 12px; }
    
    .stDownloadButton button {
        background-color: transparent !important;
        border: 1px solid #444 !important;
        color: #888 !important;
        font-size: 12px;
        padding: 5px 15px;
    }
    .stDownloadButton button:hover {
        border-color: #2979FF !important;
        color: #2979FF !important;
    }
</style>
""", unsafe_allow_html=True)

# --- 3. ä¸­æ–‡å­—ä½“åŠ è½½ï¼ˆå¤šæºä¸‹è½½ + å®Œæ•´é”™è¯¯å¤„ç†ï¼‰ ---

FONT_CACHE_PATH = "/tmp/chinese_font.ttf"

@st.cache_resource
def download_chinese_font():
    """
    ä¸‹è½½ä¸­æ–‡å­—ä½“ï¼Œä½¿ç”¨å¤šä¸ªå¤‡ç”¨æº
    """
    if os.path.exists(FONT_CACHE_PATH):
        # éªŒè¯æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆï¼ˆå¤§äº100KBï¼‰
        if os.path.getsize(FONT_CACHE_PATH) > 100000:
            return FONT_CACHE_PATH
    
    # å¤šä¸ªå­—ä½“ä¸‹è½½æºï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
    font_urls = [
        # é˜¿é‡Œå·´å·´æ™®æƒ ä½“ï¼ˆç¨³å®šæºï¼‰
        "https://at.alicdn.com/wf/webfont/gBOgdj3cVK96/T5HsHqdcLl48.ttf",
        # æ€æºé»‘ä½“ - jsDelivr CDN
        "https://cdn.jsdelivr.net/gh/AkiChase/StandardFonts@1.0.0/fonts/SourceHanSansCN-Bold.ttf",
        # å¤‡ç”¨ï¼šGoogle Fonts æ€æºé»‘ä½“
        "https://fonts.gstatic.com/ea/notosanssc/v3/NotoSansSC-Bold.otf",
    ]
    
    for i, url in enumerate(font_urls):
        try:
            st.info(f"æ­£åœ¨ä¸‹è½½ä¸­æ–‡å­—ä½“... (æº {i+1}/{len(font_urls)})")
            
            # è®¾ç½®è¶…æ—¶å’Œ headers
            request = urllib.request.Request(
                url,
                headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
            )
            
            with urllib.request.urlopen(request, timeout=30) as response:
                font_data = response.read()
                
                # éªŒè¯ä¸‹è½½çš„æ•°æ®
                if len(font_data) < 100000:  # å­—ä½“æ–‡ä»¶åº”è¯¥å¤§äº100KB
                    continue
                    
                with open(FONT_CACHE_PATH, 'wb') as f:
                    f.write(font_data)
                
                # éªŒè¯å†™å…¥æˆåŠŸ
                if os.path.exists(FONT_CACHE_PATH) and os.path.getsize(FONT_CACHE_PATH) > 100000:
                    st.success("âœ… å­—ä½“ä¸‹è½½æˆåŠŸï¼")
                    return FONT_CACHE_PATH
                    
        except Exception as e:
            st.warning(f"æº {i+1} ä¸‹è½½å¤±è´¥: {str(e)[:50]}")
            continue
    
    return None

@st.cache_resource
def get_font(size):
    """
    è·å–æŒ‡å®šå¤§å°çš„ä¸­æ–‡å­—ä½“
    """
    font_path = download_chinese_font()
    
    if font_path and os.path.exists(font_path):
        try:
            font = ImageFont.truetype(font_path, size)
            # æµ‹è¯•å­—ä½“æ˜¯å¦æ”¯æŒä¸­æ–‡
            test_img = Image.new('RGB', (100, 100))
            test_draw = ImageDraw.Draw(test_img)
            test_draw.text((0, 0), "æµ‹è¯•", font=font)
            return font
        except Exception as e:
            st.warning(f"å­—ä½“åŠ è½½å¤±è´¥: {e}")
    
    # æœ€åå¤‡ç”¨ï¼šä½¿ç”¨ Pillow é»˜è®¤å­—ä½“ï¼ˆä¸æ”¯æŒä¸­æ–‡ï¼Œä½†ä¸ä¼šæŠ¥é”™ï¼‰
    st.error("âš ï¸ ä¸­æ–‡å­—ä½“åŠ è½½å¤±è´¥ï¼Œæ–‡å­—å¯èƒ½æ— æ³•æ­£ç¡®æ˜¾ç¤º")
    return ImageFont.load_default()

# --- 4. æ ¸å¿ƒé€»è¾‘å‡½æ•° ---

def get_image_base64(image_array):
    img = Image.fromarray(cv2.cvtColor(image_array, cv2.COLOR_BGR2RGB))
    buffer = io.BytesIO()
    img.save(buffer, format="JPEG")
    return base64.b64encode(buffer.getvalue()).decode('utf-8')

def convert_frame_to_bytes(frame_array):
    img = Image.fromarray(cv2.cvtColor(frame_array, cv2.COLOR_BGR2RGB))
    buf = io.BytesIO()
    img.save(buf, format="PNG")
    return buf.getvalue()

def get_frame_at_time(video_path, time_sec=1.5):
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    if fps == 0: fps = 30.0
    frame_id = int(fps * time_sec)
    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_id)
    ret, frame = cap.read()
    cap.release()
    return frame if ret else None

def get_video_info(video_path):
    """è·å–è§†é¢‘å°ºå¯¸å’Œæ—¶é•¿"""
    cap = cv2.VideoCapture(video_path)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    duration = frame_count / fps if fps > 0 else 0
    cap.release()
    return width, height, duration, fps

def detect_scenes_ignore_subtitles(video_path, threshold=30.0):
    cap = cv2.VideoCapture(video_path)
    frames = []
    timestamps = []
    prev_hist = None
    frame_count = 0
    fps = cap.get(cv2.CAP_PROP_FPS)
    if fps == 0: fps = 30.0 
    while True:
        ret, frame = cap.read()
        if not ret: break
        if frame_count % 15 == 0: 
            height, width, _ = frame.shape
            crop_h = int(height * 0.8) 
            cropped_frame = frame[0:crop_h, :] 
            hsv = cv2.cvtColor(cropped_frame, cv2.COLOR_BGR2HSV)
            hist = cv2.calcHist([hsv], [0, 1], None, [180, 256], [0, 180, 0, 256])
            cv2.normalize(hist, hist, 0, 1, cv2.NORM_MINMAX)
            if prev_hist is None:
                frames.append(frame)
                timestamps.append(frame_count / fps)
                prev_hist = hist
            else:
                score = cv2.compareHist(prev_hist, hist, cv2.HISTCMP_CORREL)
                if (1 - score) > (threshold / 100.0) and (frame_count / fps - timestamps[-1] > 1.5):
                    frames.append(frame)
                    timestamps.append(frame_count / fps)
                    prev_hist = hist
        frame_count += 1
    cap.release()
    return frames, timestamps

def analyze_image_reverse_engineering(image_base64):
    client = OpenAI(api_key=VISION_API_KEY, base_url=VISION_BASE_URL)
    system_prompt = """
    ä½ æ˜¯ä¸€ä½é¡¶çº§çš„ AI ç»˜ç”»æç¤ºè¯å·¥ç¨‹å¸ˆï¼ˆPrompt Engineerï¼‰ï¼Œç²¾é€š Midjourneyã€Stable Diffusion å’Œ Flux çš„æç¤ºè¯é€»è¾‘ã€‚
    è¯·æ·±åº¦å‰–æè¿™å¼ å›¾ç‰‡ï¼Œåæ¨å‡ºèƒ½å®Œç¾è¿˜åŸè¯¥ç”»é¢çš„æç¤ºè¯ã€‚
    
    è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºï¼ˆä¸è¦ Markdownï¼‰ï¼š
    {
        "style": "è¿™é‡Œåˆ—å‡ºæ ¸å¿ƒè‰ºæœ¯é£æ ¼ã€‚ä¾‹å¦‚ï¼šCyberpunk, Ukiyo-e, Oil Painting, 3D Render (Octane), Pixar Style, Matte Painting...",
        "shot": "è¿™é‡Œåˆ—å‡ºé•œå¤´ä¸å…‰å½±ã€‚ä¾‹å¦‚ï¼šWide angle, Telephoto lens, Dutch angle, Volumetric lighting, Rim light, Bokeh...",
        "prompt": "è¿™é‡Œç¼–å†™ä¸€æ®µé«˜è´¨é‡çš„è‹±æ–‡ Promptã€‚å¿…é¡»åŒ…å«ï¼š
                   1. ä¸»ä½“ç»†èŠ‚ï¼ˆäº”å®˜ã€è¡£ç€æè´¨ã€è¡¨æƒ…ï¼‰ã€‚
                   2. ç¯å¢ƒç»†èŠ‚ï¼ˆèƒŒæ™¯å…ƒç´ ã€å¤©æ°”ï¼‰ã€‚
                   3. æŠ€æœ¯å‚æ•°ï¼ˆå¦‚ï¼š8k, photorealistic, masterpiece, highly detailed, unreal engine 5ï¼‰ã€‚
                   è¯·ä½¿ç”¨é€—å·åˆ†éš”çš„å…³é”®è¯å½¢å¼ã€‚"
    }
    """
    try:
        response = client.chat.completions.create(
            model=VISION_MODEL,
            messages=[{"role": "user", "content": [
                {"type": "text", "text": system_prompt},
                {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}}
            ]}],
            max_tokens=800,
        )
        content = response.choices[0].message.content.replace("```json", "").replace("```", "").strip()
        return json.loads(content)
    except Exception as e:
        return {"style": "Error", "shot": "Error", "prompt": str(e)}

def analyze_video_frame_reconstruction(image_base64):
    client = OpenAI(api_key=VISION_API_KEY, base_url=VISION_BASE_URL)
    system_prompt = """
    ä½ æ˜¯ä¸€ä¸ªé¡¶çº§çš„ AI è‰ºæœ¯å¯¼æ¼”å’Œæç¤ºè¯ä¸“å®¶ã€‚
    è¯·æ·±åº¦åˆ†æè¿™å¼ è§†é¢‘æˆªå›¾ï¼Œç›®æ ‡æ˜¯ç”Ÿæˆä¸€æ®µèƒ½è®© Midjourney/Sora å®Œç¾è¿˜åŸç”»é¢ç¥éŸµçš„è‹±æ–‡ Promptã€‚
    
    è¯·ç‰¹åˆ«æ³¨æ„ä»¥ä¸‹ç»†èŠ‚çš„æå–ï¼š
    1. **äººç‰©èº«ä»½ä¸ç‰¹å¾**ï¼šä¸è¦åªè¯´ "Person"ã€‚è¯·ä»”ç»†è§‚å¯Ÿè¡£ç€ï¼ˆå¦‚é•¿è¢ã€æ–—ç¬ ã€ç ´æ—§è¡£ç‰©ï¼‰ï¼Œåˆ¤æ–­æ˜¯å¦ä¸º Monk (åƒ§äºº), Daoist (é“å£«), Wanderer (æµæµªè€…) æˆ– Elder (è€è€…)ã€‚
    2. **æ‘„å½±ä¸è‰ºæœ¯é£æ ¼**ï¼šè¿™æ˜¯å†™å®ç…§ç‰‡ã€CGæ¸²æŸ“è¿˜æ˜¯é»‘ç™½ç”µå½±ï¼Ÿå¦‚æœæ˜¯é»‘ç™½çš„ï¼Œè¯·åŠ ä¸Š "Black and white photography, vintage style, film grain" ç­‰å…³é”®è¯ã€‚
    3. **ç¯å¢ƒä¸æ°›å›´**ï¼šæè¿°å¤©æ°”ï¼ˆé˜´æ²‰ã€è¿·é›¾ï¼‰ã€å…‰å½±ï¼ˆæŸ”å…‰ã€é€†å…‰ï¼‰åŠç”»é¢çš„æƒ…ç»ªï¼ˆå­¤ç‹¬ã€å²è¯—æ„Ÿï¼‰ã€‚
    
    è¯·ä¸¥æ ¼æŒ‰ç…§ JSON æ ¼å¼è¾“å‡ºï¼š
    {
        "cn_desc": "ä¸­æ–‡æ·±åº¦ç”»é¢æè¿°ï¼ˆå¿…é¡»æ˜ç¡®å†™å‡ºäººç‰©èº«ä»½ï¼Œå¦‚ï¼šèƒŒè´Ÿè¡Œå›Šçš„è‹¦è¡Œåƒ§/è€é“å£«ï¼Œä»¥åŠç”»é¢çš„é»‘ç™½å¤å¤è´¨æ„Ÿï¼‰",
        "en_prompt": "High-fidelity English text-to-image prompt. Include keywords for: Subject Identity (e.g., old monk, ascetic), Clothing (traditional robes), Art Style (e.g., 1920s vintage photography, black and white, grainy film), Lighting, and Atmosphere."
    }
    ä¸è¦è¾“å‡º Markdown æ ‡è®°ã€‚
    """
    try:
        response = client.chat.completions.create(
            model=VISION_MODEL,
            messages=[{"role": "user", "content": [
                {"type": "text", "text": system_prompt},
                {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}}
            ]}],
            max_tokens=800,
        )
        content = response.choices[0].message.content.replace("```json", "").replace("```", "").strip()
        return json.loads(content)
    except Exception as e:
        return {"cn_desc": "è§£æå¤±è´¥", "en_prompt": str(e)}

def transcribe_audio_api(video_path):
    try:
        with tempfile.NamedTemporaryFile(suffix=".mp3", delete=False) as temp_audio:
            audio_path = temp_audio.name
        video = VideoFileClip(video_path)
        video.audio.write_audiofile(audio_path, codec='mp3', logger=None, ffmpeg_params=["-ac", "1"])
        video.close()
        client = OpenAI(api_key=AUDIO_API_KEY, base_url=AUDIO_BASE_URL)
        with open(audio_path, "rb") as audio_file:
            transcript = client.audio.transcriptions.create(model=AUDIO_MODEL, file=audio_file, response_format="text")
        os.remove(audio_path)
        if isinstance(transcript, str):
            try:
                data = json.loads(transcript)
                if "text" in data: return data["text"]
            except: pass
            return transcript
        return transcript.text
    except Exception as e:
        return f"Audio Error: {str(e)}"

# --- 5. å¤§å­—æŠ¥ç”Ÿæˆå‡½æ•°ï¼ˆä½¿ç”¨ OpenCV é€å¸§å¤„ç†ï¼‰ ---

def generate_poster_image(width, height, line1, line2, line3, style="v1"):
    """ç”Ÿæˆå¤§å­—æŠ¥ PNG å›¾å±‚"""
    img = Image.new('RGBA', (width, height), (0, 0, 0, 0))
    draw = ImageDraw.Draw(img)
    
    # æ ¹æ®æ ·å¼è®¾ç½®å‚æ•°
    if style == "v1":
        title_size = max(int(width * 0.09), 60)
        subtitle_size = max(int(width * 0.05), 36)
        comment_size = max(int(width * 0.055), 40)
        margin_top = int(height * 0.05)
        line_spacing = int(height * 0.025)
        colors = {
            "title": (255, 255, 0, 255),
            "subtitle": (255, 255, 255, 255),
            "comment": (255, 255, 0, 255),
        }
    elif style == "v2":
        title_size = max(int(width * 0.08), 54)
        subtitle_size = max(int(width * 0.042), 30)
        comment_size = max(int(width * 0.048), 34)
        margin_top = int(height * 0.06)
        line_spacing = int(height * 0.04)
        colors = {
            "title": (255, 220, 0, 255),
            "subtitle": (200, 200, 200, 255),
            "comment": (255, 180, 0, 255),
        }
    else:  # v3
        title_size = max(int(width * 0.11), 72)
        subtitle_size = max(int(width * 0.045), 32)
        comment_size = max(int(width * 0.06), 44)
        margin_top = int(height * 0.04)
        line_spacing = int(height * 0.018)
        colors = {
            "title": (255, 255, 50, 255),
            "subtitle": (255, 255, 255, 255),
            "comment": (255, 215, 0, 255),
        }
    
    font_title = get_font(title_size)
    font_subtitle = get_font(subtitle_size)
    font_comment = get_font(comment_size)
    
    # ç»˜åˆ¶ç¬¬1è¡Œ
    bbox1 = draw.textbbox((0, 0), line1, font=font_title)
    text_width1 = bbox1[2] - bbox1[0]
    text_height1 = bbox1[3] - bbox1[1]
    x1 = (width - text_width1) // 2
    y1 = margin_top
    draw.text((x1, y1), line1, font=font_title, fill=colors["title"])
    
    # ç»˜åˆ¶ç¬¬2è¡Œ
    bbox2 = draw.textbbox((0, 0), line2, font=font_subtitle)
    text_width2 = bbox2[2] - bbox2[0]
    text_height2 = bbox2[3] - bbox2[1]
    x2 = (width - text_width2) // 2
    y2 = y1 + text_height1 + line_spacing
    draw.text((x2, y2), line2, font=font_subtitle, fill=colors["subtitle"])
    
    # ç»˜åˆ¶ç¬¬3è¡Œ
    bbox3 = draw.textbbox((0, 0), line3, font=font_comment)
    text_width3 = bbox3[2] - bbox3[0]
    x3 = (width - text_width3) // 2
    y3 = y2 + text_height2 + int(line_spacing * 1.5)
    draw.text((x3, y3), line3, font=font_comment, fill=colors["comment"])
    
    return img

def process_video_opencv(video_path, poster_img, mirror=False, high_saturation=False):
    """
    ä½¿ç”¨ OpenCV é€å¸§å¤„ç†è§†é¢‘ï¼ˆæ— éœ€ FFmpeg å‘½ä»¤è¡Œï¼‰
    """
    try:
        cap = cv2.VideoCapture(video_path)
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        if fps == 0:
            fps = 30.0
        
        # è¾“å‡ºä¸´æ—¶æ–‡ä»¶
        output_path = tempfile.NamedTemporaryFile(suffix=".mp4", delete=False).name
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
        
        # å°† PIL å›¾åƒè½¬æ¢ä¸º OpenCV æ ¼å¼ï¼ˆBGRAï¼‰
        poster_array = np.array(poster_img.convert('RGBA'))
        poster_bgra = cv2.cvtColor(poster_array, cv2.COLOR_RGBA2BGRA)
        
        # åˆ†ç¦» alpha é€šé“
        b, g, r, a = cv2.split(poster_bgra)
        poster_bgr = cv2.merge([b, g, r])
        alpha = a.astype(float) / 255.0
        alpha_3ch = cv2.merge([alpha, alpha, alpha])
        
        frame_count = 0
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            # é•œåƒå¤„ç†
            if mirror:
                frame = cv2.flip(frame, 1)
            
            # é«˜é¥±å’Œåº¦å¤„ç†
            if high_saturation:
                hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV).astype(np.float32)
                hsv[:, :, 1] = np.clip(hsv[:, :, 1] * 1.5, 0, 255)  # é¥±å’Œåº¦ x1.5
                hsv[:, :, 2] = np.clip(hsv[:, :, 2] * 1.1, 0, 255)  # äº®åº¦ x1.1
                frame = cv2.cvtColor(hsv.astype(np.uint8), cv2.COLOR_HSV2BGR)
            
            # å åŠ å¤§å­—æŠ¥ï¼ˆalpha æ··åˆï¼‰
            frame = frame.astype(float)
            blended = frame * (1 - alpha_3ch) + poster_bgr.astype(float) * alpha_3ch
            frame = blended.astype(np.uint8)
            
            out.write(frame)
            frame_count += 1
        
        cap.release()
        out.release()
        
        # æ·»åŠ éŸ³é¢‘ï¼ˆä½¿ç”¨ moviepyï¼‰
        try:
            original_video = VideoFileClip(video_path)
            if original_video.audio is not None:
                processed_video = VideoFileClip(output_path)
                final_video = processed_video.set_audio(original_video.audio)
                
                final_output = tempfile.NamedTemporaryFile(suffix=".mp4", delete=False).name
                final_video.write_videofile(final_output, codec='libx264', audio_codec='aac', logger=None)
                
                original_video.close()
                processed_video.close()
                final_video.close()
                
                os.remove(output_path)
                return final_output
            else:
                original_video.close()
                return output_path
        except Exception as e:
            st.warning(f"éŸ³é¢‘å¤„ç†å¤±è´¥ï¼Œè¾“å‡ºé™éŸ³è§†é¢‘: {e}")
            return output_path
            
    except Exception as e:
        st.error(f"è§†é¢‘å¤„ç†å¤±è´¥: {e}")
        import traceback
        st.code(traceback.format_exc())
        return None

def generate_all_videos(video_path, line1, line2, line3, use_mirror, use_saturation):
    """ç”Ÿæˆæ‰€æœ‰ç‰ˆæœ¬çš„è§†é¢‘"""
    results = []
    width, height, duration, fps = get_video_info(video_path)
    
    # ç”Ÿæˆä¸‰ä¸ªç‰ˆæœ¬çš„ PNG
    posters = {
        "V1": generate_poster_image(width, height, line1, line2, line3, "v1"),
        "V2": generate_poster_image(width, height, line1, line2, line3, "v2"),
        "V3": generate_poster_image(width, height, line1, line2, line3, "v3"),
    }
    
    # ç¡®å®šè¦å¤„ç†çš„æ•ˆæœç»„åˆ
    effect_combinations = []
    
    if not use_mirror and not use_saturation:
        effect_combinations.append(("åŸç‰ˆ", False, False))
    else:
        if use_mirror:
            effect_combinations.append(("é•œåƒ", True, False))
        if use_saturation:
            effect_combinations.append(("é«˜é¥±å’Œ", False, True))
    
    total_tasks = len(effect_combinations) * len(posters)
    current_task = 0
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for effect_name, is_mirror, is_sat in effect_combinations:
        for version, poster_img in posters.items():
            current_task += 1
            progress_bar.progress(current_task / total_tasks)
            status_text.text(f"æ­£åœ¨ç”Ÿæˆ: {effect_name} {version} ({current_task}/{total_tasks})")
            
            output_path = process_video_opencv(
                video_path, poster_img, 
                mirror=is_mirror, 
                high_saturation=is_sat
            )
            
            if output_path:
                if effect_name == "åŸç‰ˆ":
                    filename = f"å¤§å­—æŠ¥_{version}.mp4"
                else:
                    filename = f"å¤§å­—æŠ¥_{effect_name}_{version}.mp4"
                results.append((filename, output_path))
    
    progress_bar.empty()
    status_text.empty()
    return results

# --- 6. ç•Œé¢æ¸²æŸ“ ---

st.markdown("<h1>è§†å¬è¯­è¨€åˆ†æå·¥ä½œç«™</h1>", unsafe_allow_html=True)
st.markdown("<div class='subtitle'>Visual Intelligence Analysis Workstation</div>", unsafe_allow_html=True)

# Tab å¯¼èˆªåŒº
tab1, tab2, tab3, tab4 = st.tabs(["å›¾ç”Ÿæ–‡åæ¨", "è§†é¢‘æ‹†è§£", "å£æ’­æ‰’å–", "ğŸ”’ å¤§å­—æŠ¥ç”Ÿæˆ"])

# === Tab 1: å›¾ç”Ÿæ–‡ ===
with tab1:
    st.markdown("<div style='text-align:center; color:#888; margin-bottom:10px;'>AI åæ¨é£æ ¼ã€é•œå¤´è¯­è¨€åŠç”Ÿå›¾æç¤ºè¯</div>", unsafe_allow_html=True)
    
    c1, c2, c3 = st.columns([1, 2, 1])
    with c2:
        uploaded_img = st.file_uploader(" ", type=["jpg", "png"], key="img_up")

    if uploaded_img:
        with st.spinner("AI è§†è§‰å¼•æ“æ­£åœ¨è§£æ..."):
            image = Image.open(uploaded_img)
            buffered = io.BytesIO()
            image.save(buffered, format="JPEG")
            img_b64 = base64.b64encode(buffered.getvalue()).decode('utf-8')
            result = analyze_image_reverse_engineering(img_b64)
            
            st.write("")
            r1, r2 = st.columns([1, 2])
            with r1:
                st.image(uploaded_img, caption="åŸå§‹å›¾ç‰‡", use_container_width=True)
            with r2:
                st.markdown(f"""
                <div class="info-card card-style">
                    <div class="card-header pink">ğŸ¨ é£æ ¼æç¤ºè¯ (Style)</div>
                    <div class="card-content">{result.get('style', 'N/A')}</div>
                </div>
                <div class="info-card card-shot">
                    <div class="card-header yellow">ğŸ“· é•œå¤´ä¸æ™¯åˆ« (Shot)</div>
                    <div class="card-content">{result.get('shot', 'N/A')}</div>
                </div>
                <div class="info-card card-prompt">
                    <div class="card-header blue">âœ¨ AI ç”Ÿå›¾æç¤ºè¯ (Prompt)</div>
                    <div class="card-content" style="user-select: all;">{result.get('prompt', 'N/A')}</div>
                </div>
                """, unsafe_allow_html=True)

# === Tab 2: è§†é¢‘æ‹†è§£ ===
with tab2:
    st.markdown("<div style='text-align:center; color:#888; margin-bottom:10px;'>ç”Ÿæˆç”»é¢å¸§åŒè¯­æç¤ºè¯ (é€‚ç”¨äºå³æ¢¦/NanoBananaç”»é¢è¿˜åŸ)</div>", unsafe_allow_html=True)
    
    t2_c1, t2_c2, t2_c3 = st.columns([1, 2, 1])
    with t2_c2:
        v_file = st.file_uploader(" ", type=["mp4", "mov"], key="v_up")
        threshold = st.slider("åˆ‡é•œçµæ•åº¦", 10, 60, 25)

    if v_file:
        tfile = tempfile.NamedTemporaryFile(delete=False)
        tfile.write(v_file.read())
        
        with st.status("æ­£åœ¨é€å¸§åˆ†æä¸ç”Ÿæˆæç¤ºè¯...", expanded=True) as status:
            frames, tstamps = detect_scenes_ignore_subtitles(tfile.name, threshold)
            st.write(f"æ£€æµ‹åˆ° {len(frames)} ä¸ªå…³é”®é•œå¤´ï¼Œæ­£åœ¨ç”Ÿæˆè¿˜åŸ Prompt...")
            
            res_container = st.container()
            for i, (frm, ts) in enumerate(zip(frames, tstamps)):
                b64 = get_image_base64(frm)
                res = analyze_video_frame_reconstruction(b64)
                
                with res_container:
                    res_c1, res_c2 = st.columns([2, 3])
                    
                    with res_c1:
                        st.image(frm, channels="BGR", use_container_width=True)
                        img_bytes = convert_frame_to_bytes(frm)
                        st.download_button(
                            label="ğŸ“¥ ä¸‹è½½è¯¥å¸§",
                            data=img_bytes,
                            file_name=f"frame_{ts:.2f}.png",
                            mime="image/png",
                            key=f"dl_{ts}"
                        )
                        st.caption(f"â±ï¸ æ—¶é—´ç‚¹: {ts:.2f}s")
                        
                    with res_c2:
                        st.markdown(f"""
                        <div class="info-card card-cn" style="margin-bottom:10px;">
                            <div class="card-header purple">ğŸ“ ä¸­æ–‡ç”»é¢æè¿°</div>
                            <div class="card-content">{res.get('cn_desc', '...')}</div>
                        </div>
                        <div class="info-card card-prompt">
                            <div class="card-header blue">âœ¨ ç”»é¢è¿˜åŸ Prompt (Image Gen)</div>
                            <div class="card-content" style="user-select: all;">{res.get('en_prompt', '...')}</div>
                        </div>
                        """, unsafe_allow_html=True)
                    st.divider()
            status.update(label="âœ… åˆ†æå®Œæˆ", state="complete", expanded=False)

# === Tab 3: å£æ’­æ‰’å– ===
with tab3:
    st.markdown("<div style='text-align:center; color:#888; margin-bottom:10px;'>æå–è¯­éŸ³ï¼Œè½¬æ¢ä¸ºé€å­—ç¨¿</div>", unsafe_allow_html=True)
    
    t3_c1, t3_c2, t3_c3 = st.columns([1, 2, 1])
    with t3_c2:
        a_file = st.file_uploader(" ", type=["mp4", "mp3", "wav"], key="a_up")
    
    if a_file:
        tfile_a = tempfile.NamedTemporaryFile(delete=False)
        tfile_a.write(a_file.read())
        with st.spinner("AI å¬å†™ä¸­..."):
            txt = transcribe_audio_api(tfile_a.name)
            
            r3_c1, r3_c2, r3_c3 = st.columns([1, 6, 1])
            with r3_c2:
                st.audio(a_file)
                st.markdown(f"""
                <div class="info-card card-audio">
                    <div class="card-header green">ğŸ™ï¸ é€å­—ç¨¿ (Transcript)</div>
                    <div class="card-content" style="user-select: all;">{txt}</div>
                </div>
                """, unsafe_allow_html=True)

# === Tab 4: å¤§å­—æŠ¥ç”Ÿæˆï¼ˆéœ€ç™»å½•ï¼‰ ===
with tab4:
    st.markdown("<div style='text-align:center; color:#888; margin-bottom:10px;'>ğŸ” å›¢é˜Ÿä¸“ç”¨åŠŸèƒ½ - è‡ªåŠ¨ç”Ÿæˆå¤§å­—æŠ¥è§†é¢‘</div>", unsafe_allow_html=True)
    
    if not check_login():
        login_c1, login_c2, login_c3 = st.columns([1, 1.5, 1])
        with login_c2:
            st.markdown("""
            <div style="text-align:center; margin: 30px 0;">
                <span style="font-size: 3rem;">ğŸ”</span>
                <h3 style="margin-top: 10px;">å›¢é˜Ÿæˆå‘˜ç™»å½•</h3>
            </div>
            """, unsafe_allow_html=True)
            
            username = st.text_input("è´¦å·", placeholder="è¯·è¾“å…¥è´¦å·")
            password = st.text_input("å¯†ç ", type="password", placeholder="è¯·è¾“å…¥å¯†ç ")
            
            if st.button("ç™» å½•", use_container_width=True):
                if username in USERS and USERS[username] == password:
                    st.session_state["logged_in"] = True
                    st.session_state["username"] = username
                    st.success(f"âœ… æ¬¢è¿å›æ¥ï¼Œ{username}ï¼")
                    st.rerun()
                else:
                    st.error("âŒ è´¦å·æˆ–å¯†ç é”™è¯¯")
    else:
        current_user = get_current_user()
        
        user_col1, user_col2 = st.columns([6, 1])
        with user_col1:
            st.markdown(f"<div style='color:#00BCD4;'>ğŸ‘¤ å½“å‰ç”¨æˆ·: <b>{current_user}</b></div>", unsafe_allow_html=True)
        with user_col2:
            if st.button("é€€å‡ºç™»å½•"):
                st.session_state["logged_in"] = False
                st.session_state["username"] = None
                st.rerun()
        
        st.divider()
        
        main_c1, main_c2 = st.columns([1, 1])
        
        with main_c1:
            st.markdown("### ğŸ“¤ ä¸Šä¼ è§†é¢‘")
            poster_video = st.file_uploader("æ‹–å…¥ MP4 æ–‡ä»¶", type=["mp4", "mov"], key="poster_video")
            
            if poster_video:
                st.video(poster_video)
        
        with main_c2:
            st.markdown("### âœï¸ è¾“å…¥æ–‡å­—ï¼ˆ3è¡Œï¼‰")
            line1 = st.text_input("ç¬¬1è¡Œï¼ˆé»„è‰²å¤§æ ‡é¢˜ï¼‰", value="ä¸‰å›½&æ¨¡æ‹Ÿ&ç»è¥", placeholder="ä¾‹ï¼šä¸‰å›½&æ¨¡æ‹Ÿ&ç»è¥")
            line2 = st.text_input("ç¬¬2è¡Œï¼ˆç™½è‰²å‰¯æ ‡é¢˜ï¼‰", value="ä¸€æ¬¾ä»¥æ¨¡æ‹Ÿç»è¥ä¸ºæ ¸å¿ƒçš„ç°ä»£ä¸‰å›½æ‰‹æ¸¸", placeholder="ä¾‹ï¼šä¸€æ¬¾ä»¥æ¨¡æ‹Ÿç»è¥ä¸ºæ ¸å¿ƒçš„...")
            line3 = st.text_input("ç¬¬3è¡Œï¼ˆé»„è‰²è¯„è®ºï¼‰", value="ç©å®¶ï¼šç©äº†ä¸‰å¤©è¿˜åœ¨æ–°æ‰‹æ‘ç»è¥æœ¨æå‚", placeholder="ä¾‹ï¼šç©å®¶ï¼šç©äº†ä¸‰å¤©...")
            
            st.markdown("### âš™ï¸ ç‰¹æ•ˆé€‰é¡¹")
            col_opt1, col_opt2 = st.columns(2)
            with col_opt1:
                use_mirror = st.checkbox("ğŸ”„ é•œåƒå¤„ç†", help="æ°´å¹³ç¿»è½¬è§†é¢‘")
            with col_opt2:
                use_saturation = st.checkbox("ğŸŒˆ é«˜é¥±å’Œé«˜äº®åº¦", help="æå‡ç”»é¢é²œè‰³åº¦")
        
        st.divider()
        
        # é¢„è§ˆåŒºåŸŸ
        if poster_video and line1:
            st.markdown("### ğŸ‘ï¸ æ ·å¼é¢„è§ˆ")
            
            temp_video = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
            temp_video.write(poster_video.read())
            poster_video.seek(0)
            
            width, height, _, _ = get_video_info(temp_video.name)
            
            preview_cols = st.columns(3)
            
            posters = [
                ("V1 æ ‡å‡†", generate_poster_image(width, height, line1, line2, line3, "v1")),
                ("V2 èˆ’æœ—", generate_poster_image(width, height, line1, line2, line3, "v2")),
                ("V3 å†²å‡»", generate_poster_image(width, height, line1, line2, line3, "v3")),
            ]
            
            bg_frame = get_frame_at_time(temp_video.name, 0.5)
            
            for i, (name, poster) in enumerate(posters):
                with preview_cols[i]:
                    if bg_frame is not None:
                        bg_img = Image.fromarray(cv2.cvtColor(bg_frame, cv2.COLOR_BGR2RGB)).convert("RGBA")
                        bg_img = bg_img.resize((width, height))
                        preview = Image.alpha_composite(bg_img, poster)
                        st.image(preview, caption=name, use_container_width=True)
                    else:
                        black_bg = Image.new('RGBA', (width, height), (0, 0, 0, 255))
                        preview = Image.alpha_composite(black_bg, poster)
                        st.image(preview, caption=name, use_container_width=True)
        
        st.divider()
        
        gen_c1, gen_c2, gen_c3 = st.columns([1, 2, 1])
        with gen_c2:
            generate_btn = st.button("ğŸš€ ç”Ÿæˆå¤§å­—æŠ¥è§†é¢‘", use_container_width=True, type="primary")
        
        if generate_btn and poster_video:
            options_str = []
            if use_mirror: options_str.append("é•œåƒ")
            if use_saturation: options_str.append("é«˜é¥±å’Œ")
            log_usage(current_user, "å¤§å­—æŠ¥ç”Ÿæˆ", ", ".join(options_str) if options_str else "æ— ç‰¹æ•ˆ")
            
            with st.status("æ­£åœ¨ç”Ÿæˆè§†é¢‘...", expanded=True) as status:
                temp_input = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
                poster_video.seek(0)
                temp_input.write(poster_video.read())
                temp_input.close()
                
                st.write("ğŸ“ è¯»å–è§†é¢‘ä¿¡æ¯...")
                st.write("ğŸ¨ ç”Ÿæˆå¤§å­—æŠ¥ PNG...")
                st.write("ğŸ¬ åˆæˆè§†é¢‘ï¼ˆè¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼‰...")
                
                results = generate_all_videos(
                    temp_input.name, 
                    line1, line2, line3,
                    use_mirror, use_saturation
                )
                
                status.update(label=f"âœ… ç”Ÿæˆå®Œæˆï¼å…± {len(results)} ä¸ªè§†é¢‘", state="complete")
            
            if results:
                st.markdown("### ğŸ“¥ ä¸‹è½½ç”Ÿæˆçš„è§†é¢‘")
                
                download_cols = st.columns(3)
                for i, (filename, filepath) in enumerate(results):
                    with download_cols[i % 3]:
                        with open(filepath, "rb") as f:
                            st.download_button(
                                label=f"ğŸ“¥ {filename}",
                                data=f.read(),
                                file_name=filename,
                                mime="video/mp4",
                                key=f"dl_poster_{i}"
                            )
                
                if len(results) > 1:
                    st.divider()
                    zip_buffer = io.BytesIO()
                    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zf:
                        for filename, filepath in results:
                            zf.write(filepath, filename)
                    
                    st.download_button(
                        label="ğŸ“¦ æ‰“åŒ…ä¸‹è½½å…¨éƒ¨",
                        data=zip_buffer.getvalue(),
                        file_name="å¤§å­—æŠ¥è§†é¢‘åˆé›†.zip",
                        mime="application/zip",
                        use_container_width=True
                    )
                
                for _, filepath in results:
                    try:
                        os.remove(filepath)
                    except:
                        pass
